{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "gather": {
     "logged": 1608467191232
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Workspace name: machinelearning\n",
      "Azure region: eastus2\n",
      "Subscription id: cdbe0b43-92a0-4715-838a-f2648cc7ad21\n",
      "Resource group: aml-quickstarts-164810\n",
      "Workspace.create(name='machinelearning', subscription_id='cdbe0b43-92a0-4715-838a-f2648cc7ad21', resource_group='aml-quickstarts-164810')\n"
     ]
    }
   ],
   "source": [
    "from azureml.core import Workspace, Experiment\n",
    "\n",
    "# ws = Workspace.get(name=\"udacity-project\")--> This can only work if I create a workspace named \"udacity-project\" in the Azure ML studio .\n",
    "ws = Workspace.from_config()\n",
    "exp = Experiment(workspace=ws, name=\"udacity-project\")\n",
    "\n",
    "print('Workspace name: ' + ws.name, \n",
    "      'Azure region: ' + ws.location, \n",
    "      'Subscription id: ' + ws.subscription_id, \n",
    "      'Resource group: ' + ws.resource_group, sep = '\\n')\n",
    "\n",
    "run = exp.start_logging()\n",
    "print(ws)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "gather": {
     "logged": 1608467212734
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing cluster, use it.\n",
      "Succeeded\n",
      "AmlCompute wait for completion finished\n",
      "\n",
      "Minimum number of nodes requested have been provisioned\n",
      "{'currentNodeCount': 4, 'targetNodeCount': 4, 'nodeStateCounts': {'preparingNodeCount': 0, 'runningNodeCount': 1, 'idleNodeCount': 3, 'unusableNodeCount': 0, 'leavingNodeCount': 0, 'preemptedNodeCount': 0}, 'allocationState': 'Steady', 'allocationStateTransitionTime': '2021-12-01T10:34:07.873000+00:00', 'errors': None, 'creationTime': '2021-12-01T10:27:59.489261+00:00', 'modifiedTime': '2021-12-01T10:28:15.017237+00:00', 'provisioningState': 'Succeeded', 'provisioningStateTransitionTime': None, 'scaleSettings': {'minNodeCount': 0, 'maxNodeCount': 4, 'nodeIdleTimeBeforeScaleDown': 'PT1800S'}, 'vmPriority': 'Dedicated', 'vmSize': 'STANDARD_D2_V2'}\n"
     ]
    }
   ],
   "source": [
    "from azureml.core.compute import ComputeTarget, AmlCompute\n",
    "from azureml.core.compute_target import ComputeTargetException\n",
    "\n",
    "# TODO: Create compute cluster\n",
    "# Use vm_size = \"Standard_D2_V2\" in your provisioning configuration.\n",
    "# max_nodes should be no greater than 4.\n",
    "\n",
    "# Choose a name for the cluster\n",
    "cpu_cluster_name = \"compute-cluster\"\n",
    "\n",
    "# Verify that cluster does not exist already\n",
    "try:\n",
    "    compute_target = ComputeTarget(workspace=ws, name=cpu_cluster_name)\n",
    "    print('Found existing cluster, use it.')\n",
    "except ComputeTargetException:\n",
    "    print('Creating a new compute cluster...')\n",
    "    compute_config = AmlCompute.provisioning_configuration(vm_size='STANDARD_D2_V2', max_nodes=4)\n",
    "    compute_target = ComputeTarget.create(ws, cpu_cluster_name, compute_config)\n",
    "\n",
    "# Can poll for a minimum number of nodes and for a specific timeout. \n",
    "# If no min node count is provided it uses the scale settings for the cluster.\n",
    "compute_target.wait_for_completion(show_output=True)\n",
    "\n",
    "# use get_status() to get a detailed status for the current cluster. \n",
    "print(compute_target.get_status().serialize())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "gather": {
     "logged": 1608466016239
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'SKLearn' estimator is deprecated. Please use 'ScriptRunConfig' from 'azureml.core.script_run_config' with your own defined environment or the AzureML-Tutorial curated environment.\n",
      "'enabled' is deprecated. Please use the azureml.core.runconfig.DockerConfiguration object with the 'use_docker' param instead.\n"
     ]
    }
   ],
   "source": [
    "# from azureml.widgets import RunDetails\n",
    "from azureml.train.sklearn import SKLearn\n",
    "from azureml.train.hyperdrive.run import PrimaryMetricGoal\n",
    "from azureml.train.hyperdrive.policy import BanditPolicy\n",
    "from azureml.train.hyperdrive.sampling import RandomParameterSampling\n",
    "from azureml.train.hyperdrive.runconfig import HyperDriveConfig\n",
    "from azureml.train.hyperdrive.parameter_expressions import choice, uniform\n",
    "import os\n",
    "\n",
    "# Specify parameter sampler\n",
    "\n",
    "ps = RandomParameterSampling(\n",
    "    {\n",
    "        '--C' : choice(0.001,0.01,0.1,1,10,20,50,100,200,500,1000),\n",
    "        '--max_iter': choice(50,100,200,300)\n",
    "    }\n",
    ")\n",
    "\n",
    "# Specify a Policy\n",
    "policy = BanditPolicy(evaluation_interval=2, slack_factor=0.1)\n",
    "\n",
    "if \"training\" not in os.listdir():\n",
    "    os.mkdir(\"./training\")\n",
    "\n",
    "# Create a SKLearn estimator for use with train.py\n",
    "est = SKLearn(source_directory = \"./\",\n",
    "            compute_target=compute_target,\n",
    "            vm_size='STANDARD_D2_V2',\n",
    "            entry_script=\"train.py\")\n",
    "\n",
    "# Create a HyperDriveConfig using the estimator, hyperparameter sampler, and policy.\n",
    "hyperdrive_config = HyperDriveConfig(hyperparameter_sampling=ps, \n",
    "                                     primary_metric_name='Accuracy',\n",
    "                                     primary_metric_goal=PrimaryMetricGoal.MAXIMIZE,\n",
    "                                     policy=policy,\n",
    "                                     estimator=est,\n",
    "                                     max_total_runs=16,\n",
    "                                     max_concurrent_runs=4)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "gather": {
     "logged": 1608466752166
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:If 'script' has been provided here and a script file name has been specified in 'run_config', 'script' provided in ScriptRunConfig initialization will take precedence.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RunId: HD_c260886c-66b0-49ad-9748-fa40addd61a5\n",
      "Web View: https://ml.azure.com/runs/HD_c260886c-66b0-49ad-9748-fa40addd61a5?wsid=/subscriptions/cdbe0b43-92a0-4715-838a-f2648cc7ad21/resourcegroups/aml-quickstarts-164810/workspaces/machinelearning&tid=660b3398-b80e-49d2-bc5b-ac1dc93b5254\n",
      "\n",
      "Streaming azureml-logs/hyperdrive.txt\n",
      "=====================================\n",
      "\n",
      "\"<START>[2021-12-01T10:29:18.034197][API][INFO]Experiment created<END>\\n\"\"<START>[2021-12-01T10:29:18.978921][GENERATOR][INFO]Trying to sample '4' jobs from the hyperparameter space<END>\\n\"\"<START>[2021-12-01T10:29:19.122743][GENERATOR][INFO]Successfully sampled '4' jobs, they will soon be submitted to the execution target.<END>\\n\"\n",
      "\n",
      "Execution Summary\n",
      "=================\n",
      "RunId: HD_c260886c-66b0-49ad-9748-fa40addd61a5\n",
      "Web View: https://ml.azure.com/runs/HD_c260886c-66b0-49ad-9748-fa40addd61a5?wsid=/subscriptions/cdbe0b43-92a0-4715-838a-f2648cc7ad21/resourcegroups/aml-quickstarts-164810/workspaces/machinelearning&tid=660b3398-b80e-49d2-bc5b-ac1dc93b5254\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Submit your hyperdrive run to the experiment and show run details with the widget.\n",
    "\n",
    "# Start the HyperDrive run\n",
    "hyperdrive_run = exp.submit(hyperdrive_config)\n",
    "\n",
    "# Monitor HyperDrive runs You can monitor the progress of the runs with the following Jupyter widget\n",
    "# RunDetails(hyperdrive_run).show()\n",
    "\n",
    "hyperdrive_run.wait_for_completion(show_output=True)\n",
    "\n",
    "assert(hyperdrive_run.get_status() == \"Completed\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "gather": {
     "logged": 1608466755917
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'run_id': 'HD_c260886c-66b0-49ad-9748-fa40addd61a5_7', 'hyperparameters': None, 'best_primary_metric': 0.9176024279210926, 'status': 'Completed'}, {'run_id': 'HD_c260886c-66b0-49ad-9748-fa40addd61a5_13', 'hyperparameters': None, 'best_primary_metric': 0.9163884673748103, 'status': 'Completed'}, {'run_id': 'HD_c260886c-66b0-49ad-9748-fa40addd61a5_9', 'hyperparameters': None, 'best_primary_metric': 0.9163884673748103, 'status': 'Completed'}, {'run_id': 'HD_c260886c-66b0-49ad-9748-fa40addd61a5_0', 'hyperparameters': '{\"--C\": 0.1, \"--max_iter\": 300}', 'best_primary_metric': 0.9163884673748103, 'status': 'Completed'}, {'run_id': 'HD_c260886c-66b0-49ad-9748-fa40addd61a5_14', 'hyperparameters': None, 'best_primary_metric': 0.9162367223065251, 'status': 'Completed'}, {'run_id': 'HD_c260886c-66b0-49ad-9748-fa40addd61a5_8', 'hyperparameters': None, 'best_primary_metric': 0.9162367223065251, 'status': 'Completed'}, {'run_id': 'HD_c260886c-66b0-49ad-9748-fa40addd61a5_3', 'hyperparameters': '{\"--C\": 20, \"--max_iter\": 300}', 'best_primary_metric': 0.9162367223065251, 'status': 'Completed'}, {'run_id': 'HD_c260886c-66b0-49ad-9748-fa40addd61a5_5', 'hyperparameters': None, 'best_primary_metric': 0.9162367223065251, 'status': 'Completed'}, {'run_id': 'HD_c260886c-66b0-49ad-9748-fa40addd61a5_6', 'hyperparameters': None, 'best_primary_metric': 0.9162367223065251, 'status': 'Completed'}, {'run_id': 'HD_c260886c-66b0-49ad-9748-fa40addd61a5_1', 'hyperparameters': '{\"--C\": 20, \"--max_iter\": 100}', 'best_primary_metric': 0.9162367223065251, 'status': 'Completed'}, {'run_id': 'HD_c260886c-66b0-49ad-9748-fa40addd61a5_11', 'hyperparameters': None, 'best_primary_metric': 0.9159332321699545, 'status': 'Completed'}, {'run_id': 'HD_c260886c-66b0-49ad-9748-fa40addd61a5_10', 'hyperparameters': None, 'best_primary_metric': 0.9159332321699545, 'status': 'Completed'}, {'run_id': 'HD_c260886c-66b0-49ad-9748-fa40addd61a5_15', 'hyperparameters': None, 'best_primary_metric': 0.9157814871016692, 'status': 'Completed'}, {'run_id': 'HD_c260886c-66b0-49ad-9748-fa40addd61a5_12', 'hyperparameters': None, 'best_primary_metric': 0.9157814871016692, 'status': 'Completed'}, {'run_id': 'HD_c260886c-66b0-49ad-9748-fa40addd61a5_4', 'hyperparameters': None, 'best_primary_metric': 0.9157814871016692, 'status': 'Completed'}, {'run_id': 'HD_c260886c-66b0-49ad-9748-fa40addd61a5_2', 'hyperparameters': '{\"--C\": 0.001, \"--max_iter\": 200}', 'best_primary_metric': 0.9157814871016692, 'status': 'Completed'}]\n",
      "Best run metrics : {'Regularization Strength:': 100.0, 'Max iterations:': 200, 'Accuracy': 0.9176024279210926}\n",
      "Best run details : {'runId': 'HD_c260886c-66b0-49ad-9748-fa40addd61a5_7', 'target': 'compute-cluster', 'status': 'Completed', 'startTimeUtc': '2021-12-01T10:37:23.459119Z', 'endTimeUtc': '2021-12-01T10:38:44.784805Z', 'services': {}, 'warnings': [{'message': 'This run might be using a new job runtime with improved performance and error reporting. The logs from your script are in user_logs/std_log.txt. Please let us know if you run into any issues, and if you would like to opt-out, please add the environment variable AZUREML_COMPUTE_USE_COMMON_RUNTIME to the environment variables section of the job and set its value to the string \"false\"'}], 'properties': {'_azureml.ComputeTargetType': 'amlcompute', 'ContentSnapshotId': '309350bd-7b71-400b-aab0-0caf3797e15a', 'ProcessInfoFile': 'azureml-logs/process_info.json', 'ProcessStatusFile': 'azureml-logs/process_status.json'}, 'inputDatasets': [], 'outputDatasets': [], 'runDefinition': {'script': 'train.py', 'command': '', 'useAbsolutePath': False, 'arguments': ['--C', '100', '--max_iter', '200'], 'sourceDirectoryDataStore': None, 'framework': 'Python', 'communicator': 'None', 'target': 'compute-cluster', 'dataReferences': {}, 'data': {}, 'outputData': {}, 'datacaches': [], 'jobName': None, 'maxRunDurationSeconds': None, 'nodeCount': 1, 'instanceTypes': [], 'priority': None, 'credentialPassthrough': False, 'identity': None, 'environment': {'name': 'Experiment udacity-project Environment', 'version': 'Autosave_2021-12-01T10:30:18Z_3cc23f72', 'python': {'interpreterPath': 'python', 'userManagedDependencies': True, 'condaDependencies': {'name': 'project_environment', 'dependencies': ['python=3.6.2', {'pip': ['azureml-defaults']}], 'channels': ['anaconda', 'conda-forge']}, 'baseCondaEnvironment': None}, 'environmentVariables': {'EXAMPLE_ENV_VAR': 'EXAMPLE_VALUE'}, 'docker': {'baseImage': 'sklearn:0.20.3-cpu', 'platform': {'os': 'Linux', 'architecture': 'amd64'}, 'baseDockerfile': None, 'baseImageRegistry': {'address': 'viennaprivate.azurecr.io', 'username': None, 'password': None}, 'enabled': True, 'arguments': []}, 'spark': {'repositories': [], 'packages': [], 'precachePackages': False}, 'inferencingStackVersion': None}, 'history': {'outputCollection': True, 'directoriesToWatch': ['logs'], 'enableMLflowTracking': True, 'snapshotProject': True}, 'spark': {'configuration': {'spark.app.name': 'Azure ML Experiment', 'spark.yarn.maxAppAttempts': '1'}}, 'parallelTask': {'maxRetriesPerWorker': 0, 'workerCountPerNode': 1, 'terminalExitCodes': None, 'configuration': {}}, 'amlCompute': {'name': None, 'vmSize': 'STANDARD_D2_V2', 'retainCluster': False, 'clusterMaxNodeCount': 1}, 'aiSuperComputer': {'instanceType': 'AISupercomputer.D2', 'imageVersion': 'pytorch-1.7.0', 'location': None, 'aiSuperComputerStorageData': None, 'interactive': False, 'scalePolicy': None, 'virtualClusterArmId': None, 'tensorboardLogDirectory': None, 'sshPublicKey': None, 'sshPublicKeys': None, 'enableAzmlInt': True, 'priority': 'Medium', 'slaTier': 'Standard', 'userAlias': None}, 'kubernetesCompute': {'instanceType': None}, 'tensorflow': {'workerCount': 1, 'parameterServerCount': 1}, 'mpi': {'processCountPerNode': 1}, 'pyTorch': {'communicationBackend': 'nccl', 'processCount': None}, 'hdi': {'yarnDeployMode': 'Cluster'}, 'containerInstance': {'region': None, 'cpuCores': 2.0, 'memoryGb': 3.5}, 'exposedPorts': None, 'docker': {'useDocker': False, 'sharedVolumes': True, 'shmSize': '2g', 'arguments': []}, 'cmk8sCompute': {'configuration': {}}, 'commandReturnCodeConfig': {'returnCode': 'Zero', 'successfulReturnCodes': []}, 'environmentVariables': {}, 'applicationEndpoints': {}, 'parameters': [], 'dataBricks': {'workers': 0, 'minimumWorkerCount': 0, 'maxMumWorkerCount': 0, 'sparkVersion': '4.0.x-scala2.11', 'nodeTypeId': 'Standard_D3_v2', 'sparkConf': {}, 'sparkEnvVars': {}, 'instancePoolId': None, 'timeoutSeconds': 0, 'jarLibraries': [], 'eggLibraries': [], 'whlLibraries': [], 'pypiLibraries': [], 'rCranLibraries': [], 'mavenLibraries': [], 'linkedADBWorkspaceMetadata': None, 'databrickResourceId': None, 'autoScale': False}}, 'logFiles': {'logs/azureml/16_azureml.log': 'https://machinelearnin3636320337.blob.core.windows.net/azureml/ExperimentRun/dcid.HD_c260886c-66b0-49ad-9748-fa40addd61a5_7/logs/azureml/16_azureml.log?sv=2019-07-07&sr=b&sig=AMNRC6PuDUNmpbZF0r4NBvkMqUvDTZSABia93bn4eXg%3D&skoid=150f8518-b38c-4f99-ac46-3902a9bba896&sktid=660b3398-b80e-49d2-bc5b-ac1dc93b5254&skt=2021-12-01T09%3A58%3A17Z&ske=2021-12-02T18%3A08%3A17Z&sks=b&skv=2019-07-07&st=2021-12-01T10%3A34%3A06Z&se=2021-12-01T18%3A44%3A06Z&sp=r'}, 'submittedBy': 'ODL_User 164810'}\n",
      "Best run file names : ['logs/azureml/16_azureml.log', 'system_logs/cs_capability/cs-capability.log', 'system_logs/hosttools_capability/hosttools-capability.log', 'system_logs/lifecycler/execution-wrapper.log', 'system_logs/lifecycler/lifecycler.log', 'system_logs/lifecycler/vm-bootstrapper.log', 'user_logs/std_log.txt']\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "print(hyperdrive_run.get_children_sorted_by_primary_metric(top=0, reverse=False, discard_no_metric=False))\n",
    "\n",
    "# Get your best run and save the model from that run.\n",
    "\n",
    "# get_best_run_by_primary_metric()\n",
    "# Returns the best Run, or None if no child has the primary metric.\n",
    "best_run = hyperdrive_run.get_best_run_by_primary_metric()\n",
    "# get_metrics()\n",
    "# Returns the metrics from all the runs that were launched by this HyperDriveRun.\n",
    "print(\"Best run metrics :\",best_run.get_metrics())\n",
    "# get_details()\n",
    "# Returns a dictionary with the details for the run\n",
    "print(\"Best run details :\",best_run.get_details())\n",
    "# get_file_names()\n",
    "# Returns a list of the files that are stored in association with the run.\n",
    "print(\"Best run file names :\",best_run.get_file_names())\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "gather": {
     "logged": 1608467244524
    }
   },
   "outputs": [],
   "source": [
    "from azureml.data.dataset_factory import TabularDatasetFactory\n",
    "\n",
    "# Create TabularDataset using TabularDatasetFactory\n",
    "# Data is available at: \n",
    "# \"https://automlsamplenotebookdata.blob.core.windows.net/automl-sample-notebook-data/bankmarketing_train.csv\"\n",
    "\n",
    "ds = TabularDatasetFactory.from_delimited_files(['https://automlsamplenotebookdata.blob.core.windows.net/automl-sample-notebook-data/bankmarketing_train.csv'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "gather": {
     "logged": 1608467246686
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "from train import clean_data\n",
    "\n",
    "# Use the clean_data function to clean your data.\n",
    "x, y = clean_data(ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "gather": {
     "logged": 1608467249154
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "from azureml.train.automl import AutoMLConfig\n",
    "\n",
    "\n",
    "automl_config = AutoMLConfig(\n",
    "    compute_target = compute_target,\n",
    "    experiment_timeout_minutes=15,\n",
    "    task='classification',\n",
    "    primary_metric='accuracy',\n",
    "    training_data=ds,\n",
    "    label_column_name='y',\n",
    "    iteration_timeout_minutes=5,\n",
    "    n_cross_validations=2)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "gather": {
     "logged": 1608468790035
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submitting remote run.\n",
      "Running on remote compute: compute-cluster\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table style=\"width:100%\"><tr><th>Experiment</th><th>Id</th><th>Type</th><th>Status</th><th>Details Page</th><th>Docs Page</th></tr><tr><td>automl_test_experiment</td><td>AutoML_a56e8b9b-756c-4d68-807c-8d43147a2258</td><td>automl</td><td>NotStarted</td><td><a href=\"https://ml.azure.com/runs/AutoML_a56e8b9b-756c-4d68-807c-8d43147a2258?wsid=/subscriptions/cdbe0b43-92a0-4715-838a-f2648cc7ad21/resourcegroups/aml-quickstarts-164810/workspaces/machinelearning&amp;tid=660b3398-b80e-49d2-bc5b-ac1dc93b5254\" target=\"_blank\" rel=\"noopener\">Link to Azure Machine Learning studio</a></td><td><a href=\"https://docs.microsoft.com/en-us/python/api/overview/azure/ml/intro?view=azure-ml-py\" target=\"_blank\" rel=\"noopener\">Link to Documentation</a></td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Current status: FeaturesGeneration. Generating features for the dataset.\n",
      "Current status: DatasetFeaturization. Beginning to fit featurizers and featurize the dataset.\n",
      "Current status: DatasetCrossValidationSplit. Generating individually featurized CV splits.\n",
      "Current status: ModelSelection. Beginning model selection.\n",
      "\n",
      "****************************************************************************************************\n",
      "DATA GUARDRAILS: \n",
      "\n",
      "TYPE:         Class balancing detection\n",
      "STATUS:       ALERTED\n",
      "DESCRIPTION:  To decrease model bias, please cancel the current run and fix balancing problem.\n",
      "              Learn more about imbalanced data: https://aka.ms/AutomatedMLImbalancedData\n",
      "DETAILS:      Imbalanced data can lead to a falsely perceived positive effect of a model's accuracy because the input data has bias towards one class.\n",
      "+---------------------------------+---------------------------------+--------------------------------------+\n",
      "|Size of the smallest class       |Name/Label of the smallest class |Number of samples in the training data|\n",
      "+=================================+=================================+======================================+\n",
      "|3692                             |yes                              |32950                                 |\n",
      "+---------------------------------+---------------------------------+--------------------------------------+\n",
      "\n",
      "****************************************************************************************************\n",
      "\n",
      "TYPE:         Missing feature values imputation\n",
      "STATUS:       PASSED\n",
      "DESCRIPTION:  No feature missing values were detected in the training data.\n",
      "              Learn more about missing value imputation: https://aka.ms/AutomatedMLFeaturization\n",
      "\n",
      "****************************************************************************************************\n",
      "\n",
      "TYPE:         High cardinality feature detection\n",
      "STATUS:       PASSED\n",
      "DESCRIPTION:  Your inputs were analyzed, and no high cardinality features were detected.\n",
      "              Learn more about high cardinality feature handling: https://aka.ms/AutomatedMLFeaturization\n",
      "\n",
      "****************************************************************************************************\n",
      "\n",
      "****************************************************************************************************\n",
      "ITERATION: The iteration being evaluated.\n",
      "PIPELINE: A summary description of the pipeline being evaluated.\n",
      "DURATION: Time taken for the current iteration.\n",
      "METRIC: The result of computing score on the fitted pipeline.\n",
      "BEST: The best observed score thus far.\n",
      "****************************************************************************************************\n",
      "\n",
      " ITERATION   PIPELINE                                       DURATION      METRIC      BEST\n",
      "         0   MaxAbsScaler LightGBM                          0:01:22       0.9123    0.9123\n",
      "         1   MaxAbsScaler XGBoostClassifier                 0:01:37       0.9133    0.9133\n",
      "         2   MaxAbsScaler ExtremeRandomTrees                0:01:58       0.7385    0.9133\n",
      "         3   SparseNormalizer XGBoostClassifier             0:01:54       0.9126    0.9133\n",
      "         4   MaxAbsScaler LightGBM                          0:01:12       0.9124    0.9133\n",
      "         5   MaxAbsScaler LightGBM                          0:01:29       0.8880    0.9133\n",
      "         6   StandardScalerWrapper XGBoostClassifier        0:01:20       0.9077    0.9133\n",
      "         7   MaxAbsScaler LogisticRegression                0:01:09       0.9085    0.9133\n",
      "         8   StandardScalerWrapper ExtremeRandomTrees       0:00:52       0.8888    0.9133\n",
      "         9   StandardScalerWrapper XGBoostClassifier        0:01:17       0.9073    0.9133\n",
      "        10   SparseNormalizer LightGBM                      0:00:42       0.9044    0.9133\n",
      "        11    VotingEnsemble                                0:01:20       0.9159    0.9159\n",
      "        12    StackEnsemble                                 0:00:45       0.9143    0.9159\n"
     ]
    }
   ],
   "source": [
    "# Submit your automl run\n",
    "#from azureml.core.experiment import Experiment\n",
    "\n",
    "\n",
    "#remote_run = exp.submit(automl_config, show_output = False)\n",
    "from azureml.core.experiment import Experiment\n",
    "\n",
    "experiment = Experiment(ws, \"automl_test_experiment\")\n",
    "run = experiment.submit(config=automl_config, show_output=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "gather": {
     "logged": 1608468831008
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:The version of the SDK does not match the version the model was trained on.\n",
      "WARNING:root:The consistency in the result may not be guaranteed.\n",
      "WARNING:root:Package:azureml-automl-core, training version:1.35.1, current version:1.34.0\n",
      "Package:azureml-automl-runtime, training version:1.35.1, current version:1.34.0\n",
      "Package:azureml-core, training version:1.35.0.post1, current version:1.34.0\n",
      "Package:azureml-dataprep, training version:2.23.2, current version:2.22.2\n",
      "Package:azureml-dataprep-rslex, training version:1.21.2, current version:1.20.1\n",
      "Package:azureml-dataset-runtime, training version:1.35.0, current version:1.34.0\n",
      "Package:azureml-defaults, training version:1.35.0, current version:1.34.0\n",
      "Package:azureml-interpret, training version:1.35.0, current version:1.34.0\n",
      "Package:azureml-mlflow, training version:1.35.0, current version:1.34.0\n",
      "Package:azureml-pipeline-core, training version:1.35.0, current version:1.34.0\n",
      "Package:azureml-responsibleai, training version:1.35.0, current version:1.34.0\n",
      "Package:azureml-telemetry, training version:1.35.0, current version:1.34.0\n",
      "Package:azureml-train-automl-client, training version:1.35.0, current version:1.34.0\n",
      "Package:azureml-train-automl-runtime, training version:1.35.1, current version:1.34.0\n",
      "Package:azureml-train-core, training version:1.35.0, current version:1.34.0\n",
      "Package:azureml-train-restclients-hyperdrive, training version:1.35.0, current version:1.34.0\n",
      "WARNING:root:Please ensure the version of your local conda dependencies match the version on which your model was trained in order to properly retrieve your model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run(Experiment: automl_test_experiment,\n",
      "Id: AutoML_a56e8b9b-756c-4d68-807c-8d43147a2258_11,\n",
      "Type: azureml.scriptrun,\n",
      "Status: Completed)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('datatransformer',\n",
      "                 DataTransformer(enable_dnn=False, enable_feature_sweeping=True, feature_sweeping_config={}, feature_sweeping_timeout=86400, featurization_config=None, force_text_dnn=False, is_cross_validation=True, is_onnx_compatible=False, observer=None, task='classification', working_dir='/mnt/batch/tasks/shared/LS_root/mount...\n",
      "), random_state=None))], verbose=False)), ('7', Pipeline(memory=None, steps=[('maxabsscaler', MaxAbsScaler(copy=True)), ('logisticregression', LogisticRegression(C=1.7575106248547894, class_weight=None, dual=False, fit_intercept=True, intercept_scaling=1, l1_ratio=None, max_iter=100, multi_class='multinomial', n_jobs=1, penalty='l2', random_state=None, solver='lbfgs', tol=0.0001, verbose=0, warm_start=False))], verbose=False)), ('2', Pipeline(memory=None, steps=[('maxabsscaler', MaxAbsScaler(copy=True)), ('extratreesclassifier', ExtraTreesClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced', criterion='gini', max_depth=None, max_features='sqrt', max_leaf_nodes=None, max_samples=None, min_impurity_decrease=0.0, min_impurity_split=None, min_samples_leaf=0.01, min_samples_split=0.15052631578947367, min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=1, oob_score=True, random_state=None, verbose=0, warm_start=False))], verbose=False))], flatten_transform=None, weights=[0.2, 0.1, 0.1, 0.4, 0.1, 0.1]))],\n",
      "         verbose=False)\n",
      "Y_transformer(['LabelEncoder', LabelEncoder()])\n"
     ]
    }
   ],
   "source": [
    "# Retrieve and save your best automl model.\n",
    "best_run, fitted_model = run.get_output()\n",
    "print(best_run)\n",
    "print(fitted_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "gather": {
     "logged": 1608468950783
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'norm_macro_recall': 0.47640250020287644,\n",
       " 'log_loss': 0.21347504056161207,\n",
       " 'average_precision_score_micro': 0.981135104268435,\n",
       " 'AUC_micro': 0.9804655197901819,\n",
       " 'f1_score_macro': 0.7644418216052982,\n",
       " 'average_precision_score_weighted': 0.9549769380693949,\n",
       " 'recall_score_weighted': 0.9159028831562974,\n",
       " 'precision_score_macro': 0.801405392719245,\n",
       " 'AUC_macro': 0.9464806591378747,\n",
       " 'f1_score_weighted': 0.9109972573531921,\n",
       " 'matthews_correlation': 0.5357248625185906,\n",
       " 'precision_score_micro': 0.9159028831562974,\n",
       " 'recall_score_macro': 0.7382012501014382,\n",
       " 'AUC_weighted': 0.9464806591378747,\n",
       " 'precision_score_weighted': 0.908808153008863,\n",
       " 'average_precision_score_macro': 0.8238269034873813,\n",
       " 'balanced_accuracy': 0.7382012501014382,\n",
       " 'accuracy': 0.9159028831562974,\n",
       " 'weighted_accuracy': 0.9600439006800229,\n",
       " 'f1_score_micro': 0.9159028831562974,\n",
       " 'recall_score_micro': 0.9159028831562974,\n",
       " 'accuracy_table': 'aml://artifactId/ExperimentRun/dcid.AutoML_a56e8b9b-756c-4d68-807c-8d43147a2258_11/accuracy_table',\n",
       " 'confusion_matrix': 'aml://artifactId/ExperimentRun/dcid.AutoML_a56e8b9b-756c-4d68-807c-8d43147a2258_11/confusion_matrix'}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_run.get_metrics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "gather": {
     "logged": 1608468967659
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PipelineWithYTransformations(Pipeline={'memory': None,\n",
       "                                       'steps': [('datatransformer',\n",
       "                                                  DataTransformer(enable_dnn=False, enable_feature_sweeping=True, feature_sweeping_config={}, feature_sweeping_timeout=86400, featurization_config=None, force_text_dnn=False, is_cross_validation=True, is_onnx_compatible=False, observer=None, task='classification', working_dir='/mn...\n",
       "), random_state=None))], verbose=False)), ('7', Pipeline(memory=None, steps=[('maxabsscaler', MaxAbsScaler(copy=True)), ('logisticregression', LogisticRegression(C=1.7575106248547894, class_weight=None, dual=False, fit_intercept=True, intercept_scaling=1, l1_ratio=None, max_iter=100, multi_class='multinomial', n_jobs=1, penalty='l2', random_state=None, solver='lbfgs', tol=0.0001, verbose=0, warm_start=False))], verbose=False)), ('2', Pipeline(memory=None, steps=[('maxabsscaler', MaxAbsScaler(copy=True)), ('extratreesclassifier', ExtraTreesClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced', criterion='gini', max_depth=None, max_features='sqrt', max_leaf_nodes=None, max_samples=None, min_impurity_decrease=0.0, min_impurity_split=None, min_samples_leaf=0.01, min_samples_split=0.15052631578947367, min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=1, oob_score=True, random_state=None, verbose=0, warm_start=False))], verbose=False))], flatten_transform=None, weights=[0.2, 0.1, 0.1, 0.4, 0.1, 0.1]))],\n",
       "                                       'verbose': False},\n",
       "                             y_transformer={},\n",
       "                             y_transformer_name='LabelEncoder')"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fitted_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "gather": {
     "logged": 1608468990767
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table style=\"width:100%\"><tr><th>Experiment</th><th>Id</th><th>Type</th><th>Status</th><th>Details Page</th><th>Docs Page</th></tr><tr><td>automl_test_experiment</td><td>AutoML_a56e8b9b-756c-4d68-807c-8d43147a2258_11</td><td>azureml.scriptrun</td><td>Completed</td><td><a href=\"https://ml.azure.com/runs/AutoML_a56e8b9b-756c-4d68-807c-8d43147a2258_11?wsid=/subscriptions/cdbe0b43-92a0-4715-838a-f2648cc7ad21/resourcegroups/aml-quickstarts-164810/workspaces/machinelearning&amp;tid=660b3398-b80e-49d2-bc5b-ac1dc93b5254\" target=\"_blank\" rel=\"noopener\">Link to Azure Machine Learning studio</a></td><td><a href=\"https://docs.microsoft.com/en-us/python/api/azureml-core/azureml.core.run.Run?view=azure-ml-py\" target=\"_blank\" rel=\"noopener\">Link to Documentation</a></td></tr></table>"
      ],
      "text/plain": [
       "Run(Experiment: automl_test_experiment,\n",
       "Id: AutoML_a56e8b9b-756c-4d68-807c-8d43147a2258_11,\n",
       "Type: azureml.scriptrun,\n",
       "Status: Completed)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "gather": {
     "logged": 1608469075938
    }
   },
   "outputs": [],
   "source": [
    "# Cluster clean up\n",
    "\n",
    "compute_target.delete()"
   ]
  }
 ],
 "metadata": {
  "kernel_info": {
   "name": "python3"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "nteract": {
   "version": "nteract-front-end@1.0.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
